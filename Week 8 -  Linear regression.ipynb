{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 17.1\n",
    "***Purpose***: Apply linear model to quadratic data and do a\n",
    "posterior predictive check.\n",
    "### A\n",
    "Change the script `Jags-Ymet-XmetSsubj-MrobustHier-Example.R` so it uses\n",
    "the family income data (`file=\"Guber1999data.csv\"`). (Notice how simple it is to do that.)\n",
    "\n",
    "* Are the data well described by the linear model?\n",
    "* What exactly is the “systematic discrepancy” between model and data? Don’t just say, “the data are curved.” What exactly does that mean in terms of how the data deviate from the model and where?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B\n",
    "Is there a way of rejecting the linear model without reference to any othermodel?\n",
    "In other words, how might you compute a “Bayesian p value” for this situation? Should\n",
    "you? See Kruschke (2013b) for information and references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 17.2\n",
    "***Purpose***: Observe the autocorrelation in JAGS when data are\n",
    "not standardized.\n",
    "Change the (simple, nonhierarchical) JAGS program `Jags-Ymet-Xmet-Mrobust.R` so that it uses the raw data instead of the standardized data. Be sure\n",
    "to rename it so that you don’t destroy the original program.\n",
    "\n",
    "You will have to remove\n",
    "the standardization from the data block and remove the transformation to the original\n",
    "scale. Make sure that the prior is appropriate for the original scale (perhaps use the\n",
    "prior in the Stan version for guidance). Show the diagnostic graphs of the chains and\n",
    "discuss. Finally, run the chains a long time, with thinning if needed to conserve computer\n",
    "memory, and show that the chains eventually converge to the same posterior as when\n",
    "using standardized data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 17.3\n",
    "***Purpose***: Examining chain convergence in JAGS and Stan.\n",
    "\n",
    "![Figure 17.5](img/fig_17.5.png)\n",
    "\n",
    "As mentioned in Footnote 5 (p. 504), both JAGS and Stan show some difficulty converging\n",
    "when the quadratic-trend model is applied to the fictitious data of Figure 17.5. The\n",
    "JAGS programs are provided in files `Jags-Ymet-XmetSsubj-MrobustHierQuadWt-\n",
    "Example.R` and `Jags-Ymet-XmetSsubj-MrobustHierQuadWt.R`. The corresponding\n",
    "Stan programs are provided in files `Stan-Ymet-XmetSsubj-MrobustHierQuadWt-\n",
    "Example.R` and `Stan-Ymet-XmetSsubj-Mrobust HierQuadWt.R`. The Stan model\n",
    "specification is shown below so that you can study it and compare it to the JAGS version\n",
    "in Section 17.4 without having to be at your computer:\n",
    "\n",
    "```\n",
    "data {\n",
    "int<lower=1> Nsubj ;\n",
    "int<lower=1> Ntotal ;\n",
    "real y[Ntotal] ;\n",
    "real x[Ntotal] ;\n",
    "real<lower=0> w[Ntotal] ;\n",
    "int<lower=1> s[Ntotal] ;\n",
    "}\n",
    "transformed data {\n",
    "// Standardize the data:\n",
    "real zx[Ntotal] ;\n",
    "real zy[Ntotal] ;\n",
    "real zw[Ntotal] ;\n",
    "real wm ;\n",
    "real xm ;\n",
    "real ym ;\n",
    "real xsd ;\n",
    "real ysd ;\n",
    "xm <- mean(x) ;\n",
    "ym <- mean(y) ;\n",
    "wm <- mean(w) ;\n",
    "xsd <- sd(x) ;\n",
    "ysd <- sd(y) ;\n",
    "for ( i in 1:Ntotal ) { // could be vectorized...?\n",
    "zx[i] <- ( x[i] - xm ) / xsd ;\n",
    "zy[i] <- ( y[i] - ym ) / ysd ;\n",
    "zw[i] <- w[i] / wm ;\n",
    "}\n",
    "}\n",
    "parameters {\n",
    "real zbeta0[Nsubj] ;\n",
    "real zbeta1[Nsubj] ;\n",
    "real zbeta2[Nsubj] ;\n",
    "real<lower=0> zsigma ;\n",
    "real zbeta0mu ;\n",
    "real zbeta1mu ;\n",
    "real zbeta2mu ;\n",
    "real<lower=0> zbeta0sigma ;\n",
    "real<lower=0> zbeta1sigma ;\n",
    "real<lower=0> zbeta2sigma ;\n",
    "real<lower=0> nuMinusOne ;\n",
    "}\n",
    "transformed parameters {\n",
    "real<lower=0> nu ;\n",
    "real beta0[Nsubj] ;\n",
    "real beta1[Nsubj] ;\n",
    "real beta2[Nsubj] ;\n",
    "real<lower=0> sigma ;\n",
    "real beta0mu ;\n",
    "real beta1mu ;\n",
    "real beta2mu ;\n",
    "nu <- nuMinusOne+1 ;\n",
    "// Transform to original scale:\n",
    "for ( j in 1:Nsubj ) { // could be vectorized...?\n",
    "beta2[j] <- zbeta2[j]*ysd/square(xsd) ;\n",
    "beta1[j] <- zbeta1[j]*ysd/xsd - 2*zbeta2[j]*xm*ysd/square(xsd) ;\n",
    "beta0[j] <- zbeta0[j]*ysd + ym - zbeta1[j]*xm*ysd/xsd\n",
    "+ zbeta2[j]*square(xm)*ysd/square(xsd) ;\n",
    "}\n",
    "beta2mu <- zbeta2mu*ysd/square(xsd) ;\n",
    "beta1mu <- zbeta1mu*ysd/xsd - 2*zbeta2mu*xm*ysd/square(xsd) ;\n",
    "beta0mu <- zbeta0mu*ysd + ym - zbeta1mu*xm*ysd/xsd\n",
    "+ zbeta2mu*square(xm)*ysd/square(xsd) ;\n",
    "sigma <- zsigma * ysd ;\n",
    "}\n",
    "model {\n",
    "zbeta0mu ˜ normal( 0 , 10 ) ;\n",
    "zbeta1mu ˜ normal( 0 , 10 ) ;\n",
    "zbeta2mu ˜ normal( 0 , 10 ) ;\n",
    "zsigma ˜ uniform( 1.0E-3 , 1.0E+3 ) ;\n",
    "zbeta0sigma ˜ uniform( 1.0E-3 , 1.0E+3 ) ;\n",
    "zbeta1sigma ˜ uniform( 1.0E-3 , 1.0E+3 ) ;\n",
    "zbeta2sigma ˜ uniform( 1.0E-3 , 1.0E+3 ) ;\n",
    "nuMinusOne ˜ exponential(1/29.0) ;\n",
    "zbeta0 ˜ normal( zbeta0mu , zbeta0sigma ) ; // vectorized\n",
    "zbeta1 ˜ normal( zbeta1mu , zbeta1sigma ) ; // vectorized\n",
    "zbeta2 ˜ normal( zbeta2mu , zbeta2sigma ) ; // vectorized\n",
    "for ( i in 1:Ntotal ) {\n",
    "zy[i] ˜ student_t(\n",
    "nu ,\n",
    "zbeta0[s[i]] + zbeta1[s[i]] * zx[i] + zbeta2[s[i]] * square(zx[i]) ,\n",
    "zw[i]*zsigma ) ;\n",
    "}\n",
    "}\n",
    "```\n",
    "Review Section 14.4 (p. 414) for hints about programming Stan.\n",
    "### A\n",
    "Run Stan on the family-income data, so it achieves the same ESS as the JAGS\n",
    "program for the group-level trend coefficients. How long (in real time) do Stan and\n",
    "JAGS take? Does Stan more consistently converge than JAGS? Does Stan produce better\n",
    "chains for the normality and noise parameters?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B\n",
    "Now repeat on the fictitious data of Figure 17.8, which typically gives JAGS and\n",
    "Stan troubles of differing sorts as described Footnote 5 (p. 504). Try to produce examples\n",
    "of these troubles and discuss. Which type of trouble is more tolerable, autocorrelation in\n",
    "the normality parameter (in JAGS) or “bumps” in the regression coefficients (in Stan)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
